{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchscript\n",
    "> `torchscript.jit` support for `fastai` models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently only Vision and Tabular models are supported. More details on this technology can be found on the official [pytorch documentation](https://pytorch.org/docs/stable/jit.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivations: \n",
    "- What is torchscript? What is a serialized model?\n",
    "- Why one would like to export a model to another format?\n",
    "- Is it faster? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from fastcore.all import *\n",
    "from fastai.basics import *\n",
    "from fastai.learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@patch\n",
    "def requires_grad_(self:TensorBase, requires_grad=True):\n",
    "    # Workaround https://github.com/pytorch/pytorch/issues/50219\n",
    "    self.requires_grad = requires_grad\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two possible scenarios with `jit`: `trace` and `script`. \n",
    "- `torch.jit.trace` when the module has no flow control/ dynamic behaviour. (e.g. modules build with `nn.Sequential`). \n",
    "- `torch.jit.script` should be utilized when there are dynamics. (e.g. RNNs, Language models). \n",
    "As a result `trace` is tried by default. You can also have a [combination of both](https://pytorch.org/docs/stable/jit.html#mixing-tracing-and-scripting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">from Pytorch doc: In many cases either tracing or scripting is an easier approach for converting a model to TorchScript. Tracing and scripting can be composed to suit the particular requirements of a part of a model\n",
    "Scripted functions can call traced functions. This is particularly useful when you need to use control-flow around a simple feed-forward model. For instance the beam search of a sequence to sequence model will typically be written in script but can call an encoder module generated using tracing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of vision encoders are `traceable's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "mk_class('JitMode', **{o:o.lower() for o in ['Trace','Script']},\n",
    "         doc=\"All possible export modes as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['JitMode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"JitMode\" class=\"doc_header\"><code>class</code> <code>JitMode</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>JitMode</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "All possible export modes as attributes to get tab-completion and typo-proofing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(JitMode, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important thing to consider, is the serving device. If you plan on doing inference on CPU, yoou should first convert you model to CPU, and then trace-it ([ref](https://pytorch.org/docs/stable/jit.html#frequently-asked-questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def to_jit(self:Learner, fname='export.ts', mode=JitMode.Trace, device='cpu'):\n",
    "    \"Exports `learn.model` using `jit` with `mode` to `fname`\"\n",
    "    inp = self.dls.one_batch()[:self.dls.n_inp]\n",
    "    if not isinstance(inp, tuple): inp = (inp,)\n",
    "    self.model.eval()\n",
    "    self.model.to(device)\n",
    "    inp = to_device(inp, device)\n",
    "    traced_model = getattr(torch.jit, mode)(self.model, inp)\n",
    "    torch.jit.save(traced_model, learn.path/fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"Learner.to_jit\" class=\"doc_header\"><code>Learner.to_jit</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>Learner.to_jit</code>(**`fname`**=*`'export.ts'`*, **`mode`**=*`'trace'`*, **`device`**=*`'cpu'`*)\n",
       "\n",
       "Exports `learn.model` using [`jit`](/fastexport/jit.html) with `mode` to `fname`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.to_jit, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find a number of examples using `Learner.to_jit` and loading them back in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular (Multi-Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "\n",
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "    cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                 'relationship', 'race'],\n",
    "    cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "    procs = [Categorify, FillMissing, Normalize])\n",
    "\n",
    "learn = tabular_learner(dls, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#slow\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    cat,cont,_ = dls.one_batch()\n",
    "    with torch.no_grad():\n",
    "        learn.model.eval()\n",
    "        learn.model.to(cat.device)\n",
    "        probs = learn.model(cat,cont)\n",
    "    learn.to_jit(f'{tmpdir}/trace.pt', 'trace')\n",
    "    trace = torch.jit.load(f'{tmpdir}/trace.pt', map_location=cat.device)\n",
    "    trace.eval()\n",
    "    probs_jit = trace(cat,cont)\n",
    "    test_close(probs_jit, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabular models can only be exported with `torch.jit.trace`, so we'll use that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_jit('models/tab.pt', mode=JitMode.Trace, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load it back in using raw torch and pass in a batch of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.jit.load(\"models/tab.pt\")\n",
    "cat,cont,_ = dls.cpu().one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And perform inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0411, 0.0396],\n",
       "        [0.0045, 0.0858],\n",
       "        [0.0303, 0.0698]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = loaded_model(cat,cont); probs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As these are just the models, raw probabilities are returned. You still need to perform a soft or argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example using `ResNet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "def label_func(x): return x[0].isupper()\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    '.', get_image_files(path), valid_pct=0.2,\n",
    "    label_func=label_func, item_tfms=Resize(224))\n",
    "learn = cnn_learner(dls, resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#slow\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    x,_ = dls.one_batch()\n",
    "    with torch.no_grad():\n",
    "        learn.model.eval()\n",
    "        learn.model.to(x.device)\n",
    "        probs = learn.model(x)\n",
    "    learn.to_jit(f'{tmpdir}/trace.pt', 'trace')\n",
    "    trace = torch.jit.load(f'{tmpdir}/trace.pt', map_location=x.device)\n",
    "    trace.eval()\n",
    "    probs_trace = trace(x)\n",
    "    test_close(probs, probs_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `ResNet` is a vision model, `trace` should be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_jit('models/resnet.pt', mode=JitMode.Trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before we can now load it in and perform inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2017, -3.3517],\n",
       "        [ 2.8087, -2.2481],\n",
       "        [-0.2001, -2.5412]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = torch.jit.load(\"models/resnet.pt\")\n",
    "loaded_model.eval()\n",
    "x,_ = dls.cpu().one_batch()\n",
    "\n",
    "probs = loaded_model(x); probs[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
